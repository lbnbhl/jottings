- JavaSe
- Mysql
- JavaWeb
- Spring
- SpringMVC
- Mybatis
- MybatisPlus
- SpringCloud
- redis
- nginx
- linux
- rabbitMQ
- zookeeper
- netty
- jvm
- juc
- 设计模式
- git
- maven
- sentinel
- seata

### 八股复习

#### 负载均衡问题

##### 负载均衡常用处理方式

- 用户手动处理

  ![image-20230113101341029](C:\Users\Dear~柘木塘\AppData\Roaming\Typora\typora-user-images\image-20230113101341029.png)

- DNS轮询方式

  ![image-20230113102145067](C:\Users\Dear~柘木塘\AppData\Roaming\Typora\typora-user-images\image-20230113102145067.png)

- 四/七层负载均衡

  - 四层负载均衡指的是OSI七层模型中的传输层，主要是基于IP+PORT的负载均衡

    - 实现四层负载均衡的方式
      1. 硬件：F5 BIG-IP、Radware等
      2. 软件：LVS、Nginx、Hayproxy等

  - 七层负载均衡指的是在应用层，主要是基于虚拟的URL或主机IP的负载均衡

    - 实现七层负载均衡的方式
      - 软件：Nginx、Hayproxy等

  - 四层和七层负载均衡的区别：

    ~~~
    四层负载均衡数据包是在底层就进行了分发，而七层负载均衡数据包则在最顶端进行分发，所以四层负载均衡的效率比七层负载均衡的要高。
    四层负载均衡不识别域名，而七层负载均衡识别域名。
    ~~~

  - 二层是在数据链路层基于mac地址来实现负载均衡，三层是在网络层一般采用虚拟IP地址的方式实现负载均衡。

  - 实际环境采用的模式

    ~~~
    四层负载(LVS)+七层负载(Nginx)
    ~~~





##### nginx的负载均衡

- nginx的负载均衡策略
  
  Nginx的upstream支持如下六种方式的分配算法，分别是:
  
  | 算法名称   | 说明             |
  | ---------- | ---------------- |
  | 轮询       | 默认方式         |
  | weight     | 权重方式         |
  | ip_hash    | 依据ip分配方式   |
  | least_conn | 依据最少连接方式 |
  | url_hash   | 依据URL分配方式  |
  | fair       | 依据响应时间方式 |
  
- nginx为什么适合做负载均衡
  1. nginx工作在应用层，属于软件负载均衡，相比于硬件负载均衡，价格更加低廉。
  2. 使用简单，上手快。
  3. 基于c语言的实现，轻量级，高并发
  4. 支持热部署
  5. 支持心跳检查
  6. 支持多种负载均衡策略



#### 架构模式

- nginx的进程模型

  ![image-20230111100459986](C:\Users\Dear~柘木塘\AppData\Roaming\Typora\typora-user-images\image-20230111100459986.png)
  
  nginx的总体架构
  
  ![image-20230113161627228](C:\Users\Dear~柘木塘\AppData\Roaming\Typora\typora-user-images\image-20230113161627228.png)



#### keepalive

- tcp的
- nginx的



#### 缓存

##### 缓存使用场景



| 场景             | 作用                     |
| ---------------- | ------------------------ |
| 操作系统磁盘缓存 | 减少磁盘机械操作         |
| 数据库缓存       | 减少文件系统的IO操作     |
| 应用程序缓存     | 减少对数据库的查询       |
| Web服务器缓存    | 减少对应用服务器请求次数 |
| 浏览器缓存       | 减少与后台的交互次数     |

##### nginx 的缓存

- nginx的web缓存服务

  ~~~
  Nginx是从0.7.48版开始提供缓存功能。Nginx是基于Proxy Store来实现的，其原理是把URL及相关组合当做Key,在使用MD5算法对Key进行哈希，得到硬盘上对应的哈希目录路径，从而将缓存内容保存在该目录中。它可以支持任意URL连接，同时也支持404/301/302这样的非200状态码。Nginx即可以支持对指定URL或者状态码设置过期时间，也可以使用purge命令来手动清除指定URL的缓存。
  ~~~

- 正向的

- 反向代理值Buffer和Cache

##### 浏览器的缓存

- HTTP协议中和页面缓存相关的字段

  | header        | 说明                                        |
  | ------------- | ------------------------------------------- |
  | Expires       | 缓存过期的日期和时间                        |
  | Cache-Control | 设置和缓存相关的配置信息                    |
  | Last-Modified | 请求资源最后修改时间                        |
  | ETag          | 请求变量的实体标签的当前值，比如文件的MD5值 |

- 执行流程

  ![image-20230112204858750](C:\Users\Dear~柘木塘\AppData\Roaming\Typora\typora-user-images\image-20230112204858750.png)

  





#### 零拷贝

- nginx的sendfile

  - sendfile系统调用在两个文件描述符之间直接传递数据(完全在内核中操作)，从而避免了数据在内核缓冲区和用户缓冲区之间的拷贝，操作效率很高，被称之为零拷贝。

  - 原理解释

    ~~~
    read/write
    在传统的文件传输方式（read、write/send方式），具体流程细节如下：
    
    调用read函数，文件数据拷贝到内核缓冲区
    read函数返回，数据从内核缓冲区拷贝到用户缓冲区
    调用write/send函数，将数据从用户缓冲区拷贝到内核socket缓冲区
    数据从内核socket缓冲区拷贝到协议引擎中
    在这个过程当中，文件数据实际上是经过了四次拷贝操作：
    硬盘—>内核缓冲区—>用户缓冲区—>内核socket缓冲区—>协议引擎
    
    sendfile
    sendfile系统调用则提供了一种减少拷贝次数，提升文件传输性能的方法。
    
    sendfile系统调用利用DMA引擎将文件数据拷贝到内核缓冲区，之后数据被拷贝到内核socket缓冲区中
    DMA引擎将数据从内核socket缓冲区拷贝到协议引擎中
    这里没有用户态和内核态之间的切换，也没有内核缓冲区和用户缓冲区之间的拷贝，大大提升了传输性能。
    这个过程数据经历的拷贝操作如下：
    硬盘—>内核缓冲区—>内核socket缓冲区—>协议引擎
    
    带有DMA收集拷贝功能的sendfile
    对于带有DMA收集拷贝功能的sendfile系统调用，还可以再减少一次内核缓冲区之间的拷贝。具体流程如下：
    
    sendfile系统调用利用DMA引擎将文件数据拷贝到内核缓冲区，之后，将带有文件位置和长度信息的缓冲区描述符添加到内核socket缓冲区中
    DMA引擎会将数据直接从内核缓冲区拷贝到协议引擎中
    这个过程数据经历的拷贝操作如下：
    硬盘—>内核缓冲区—>协议引擎
    
    作者：boldcautious
    链接：https://www.jianshu.com/p/70e1c396c320
    来源：简书
    著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
    ~~~

    ![image-20230112193251729](C:\Users\Dear~柘木塘\AppData\Roaming\Typora\typora-user-images\image-20230112193251729.png)

#### nginx处理http请求

- [Nginx 是如何处理 HTTP 头部的？ - 原少子杨 - SegmentFault 思否](https://segmentfault.com/a/1190000022348375)
- [万字长文！一次性弄懂 Nginx 处理 HTTP 请求的 11 个阶段 - 原少子杨 - SegmentFault 思否](https://segmentfault.com/a/1190000022709975)



#### 常见序列化方式对比

> 序列化协议的选择通常有下列一些常用的指标：
>
> 1. 通用性。是否只能用于java间序列化/反序列化，是否跨语言，跨平台。
> 2. 性能。分为空间开销和时间开销。序列化后的数据一般用于存储或网络传输，其大小是很重要的一个参数；解析的时间也影响了序列化协议的选择，如今的系统都在追求极致的性能。
> 3. 可扩展性。系统升级不可避免，某一实体的属性变更，会不会导致反序列化异常，也应该纳入序列化协议的考量范围。
> 4. 易用性。API使用是否复杂，会影响开发效率。



##### JDK自带序列化

- 优点：
  1. 由于序列化了所有信息所以相对而言更可靠
- 缺点：
  1. JDK序列化会把对象类的描述和所有属性的元数据都序列化为字节流，另外**继承的元数据也会序列化**，所以导致序列化的元素较多且字节流很大
  2. 一个实例**能直接从byte[]数组创建**，而不经过构造方法，因此，它存在一定的安全隐患
  3. **不支持跨语言调用**



##### Hessian

- 优点：
  1. 和JDK自带的序列化方式类似，Hessian采用的也是二进制协议，只不过Hessian序列化之后，字节数更小，性能更优
  2. 跨语言



##### Kryo

- 优点：
  1. Kryo 是一个高性能的序列化/反序列化工具，由于其变长存储特性并使用了字节码生成机制，拥有较高的运行速度和较小的字节码体积。
- 缺点：
  1. 只支持Java语言
  2. 线程不安全，需结合ThreadLocal使用
  3. **Kryo不支持Bean中增删字段**
  4. **不支持包含无参构造器类的反序列化**
  5. Kryo使用注册行为最大的问题在于，其不保证同一个Class每一次注册的号码相同，意味着在不同的机器、同一个机器重启前后都有可能拥有不同的编号，这会导致序列化产生问题



##### Protobuf

- 优点：
  1. 非常高效，序列化后的数据很小，占用的网络带宽较少。
  2. 支持跨语言序列化，因此可以与其他语言的应用程序进行通信。
  3. 支持协议升级，可以在不中断旧版本客户端的情况下添加新字段。
- 缺点：
  1. 序列化和反序列化的速度不如Kryo和Hessian快。
  2. 对于嵌套的复杂对象，定义ProtoBuf结构可能需要更多的时间和精力。



##### ProtoStuff

- 优点：
  1. 序列化和反序列化速度较快。
  2. 支持跨语言序列化，因此可以与其他语言的应用程序进行通信。
  3. 与Protobuf相比，更容易使用和配置。
- 缺点：
  1. 不支持协议升级。
  2. 可能会出现类加载问题。



##### 总结

~~~
综上所述，每个框架都有其优点和缺点。在选择使用哪个框架时，需要考虑到应用程序的具体需求和场景。如果需要高性能，可以选择Kryo或Hessian；如果需要更小的数据大小，可以选择Protobuf；如果需要更易用的框架，则可以选择ProtoStuff。
~~~



#### JVM

- 基本数据类型的局部变量存放在 Java 虚拟机栈中的局部变量表中，基本数据类型的成员变量（未被 `static` 修饰 ）存放在 Java 虚拟机的堆中。包装类型属于对象类型，我们知道几乎所有对象实例都存在于堆中。

- 泛型的T和？

- Java语法糖

- 可变长底层

- G1垃圾回收器

- 为什么将永久代替换成元空间？

- Java虚拟机栈：栈由一个个栈帧组成，而每个栈帧中都拥有：*局部变量表*、*操作数栈*、*动态链接*、*方法返回地址*。

  ~~~java
  //局部变量表
  存放了编译期可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）
  
  //操作数栈
  主要作为方法调用的中转站使用，用于存放方法执行过程中产生的中间计算结果。另外，计算过程中产生的临时变量也会放在操作数栈中。
      
  //动态链接 
  主要服务一个方法需要调用其他方法的场景。在 Java 源文件被编译成字节码文件时，所有的变量和方法引用都作为符号引用（Symbilic Reference）保存在 Class 文件的常量池里。当一个方法要调用其他方法，需要将常量池中指向方法的符号引用转化为其在内存地址中的直接引用。动态链接的作用就是为了将符号引用转换为调用方法的直接引用。
  ~~~

- 方法区

  - 当虚拟机要使用一个类时，它需要读取并解析 Class 文件获取相关信息，再将信息存入到方法区。方法区会存储已被虚拟机加载的 **类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存等数据**。

  - **方法区和永久代以及元空间是什么关系呢？** 方法区和永久代以及元空间的关系很像 Java 中接口和类的关系，类实现了接口，这里的类就可以看作是永久代和元空间，接口可以看作是方法区，也就是说永久代以及元空间是 HotSpot 虚拟机对虚拟机规范中方法区的两种实现方式。并且，永久代是 JDK 1.8 之前的方法区实现，JDK 1.8 及以后方法区的实现变成了元空间。

  - **常量池表(Constant Pool Table)**

    ~~~java
    //存放编译期生成的各种字面量（Literal）和符号引用（Symbolic Reference）
    字面量是源代码中的固定值的表示法，即通过字面我们就能知道其值的含义。字面量包括整数、浮点数和字符串字面量，符号引用包括类符号引用、字段符号引用、方法符号引用和接口方法符号引用。
    
    常量池表会在类加载后存放到方法区的运行时常量池中。
    
    运行时常量池的功能类似于传统编程语言的符号表，尽管它包含了比典型符号表更广泛的数据。
    
    既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 错误。
    ~~~

- 堆

  ~~~
  Hotspot 遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了 survivor 区的一半时，取这个年龄和 MaxTenuringThreshold 中更小的一个值，作为新的晋升年龄阈值
  
  JDK1.7 之前，字符串常量池存放在永久代。JDK1.7 字符串常量池和静态变量从永久代移动了 Java 堆中
  
  ~~~

-  直接内存

  ~~~
  它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。
  
  本机直接内存的分配不会受到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制
  ~~~

- 堆内存诊断

  ~~~
  jps
  jmap
  jconsole
  jvirsalvm
  ~~~
  
  
  
- 常见异常

  ~~~Java
  //StackOverFlowError
  若栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。
  
  //OutOfMemoryError
  如果栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常
      
  //java.lang.OutOfMemoryError: GC Overhead Limit Exceeded 
  当 JVM 花太多时间执行垃圾回收并且只能回收很少的堆空间时，就会发生此错误。
      
  //java.lang.OutOfMemoryError: Java heap space
      假如在创建新的对象时, 堆内存中的空间不足以存放新创建的对象, 就会引发此错误。(和配置的最大堆内存有关，且受制于物理内存大小。最大堆内存可通过-Xmx参数配置，若没有特别配置，将会使用默认值，详见：Default Java 8 max heap size)
      
      
  //java.lang.OutOfMemoryError: MetaSpace
  元空间溢出
  ~~~

  

- 参数

  ~~~java
  -XX:MaxTenuringThreshold//对象晋升到老年代的年龄阈值
  -Xmx//配置最大堆内存
  -XX：MaxMetaspaceSize//标志设置最大元空间大小，默认值为 unlimited，这意味着它只受系统内存的限制。
  -XX：MetaspaceSize//调整标志定义元空间的初始大小如果未指定此标志，则 Metaspace 将根据运行时的应用程序需求动态地重新调整大小。
  -XX:PermSize=N //方法区 (永久代) 初始大小
  -XX:MaxPermSize=N //方法区 (永久代) 最大大小,超过这个值将会抛出 OutOfMemoryError 异常:java.lang.OutOfMemoryError: PermGen
  -XX:StringTableSize//设置字符串常量池大小
  -XX:+PrintGCDetails
  -XX:+UseParallelGC//使用 Parallel 收集器+ 老年代串行
  -XX:+UseParallelOldGC//使用 Parallel 收集器+ 老年代并行
  -XX:+UseAdptiveSizePolicy//Parallel Scavenge收集器可设置-XX:+UseAdptiveSizePolicy参数。当开关打开时不需要手动指定新生代的大小（-Xmn）、Eden与Survivor区的比例（-XX:SurvivorRation）、晋升老年代的对象年龄（-XX:PretenureSizeThreshold）等，虚拟机会根据系统的运行状况收集性能监控信息，动态设置这些参数以提供最优的停顿时间和最高的吞吐量，这种调节方式称为GC的自适应调节策略。
  XX:MaxGCPauseMillis //控制最大的垃圾收集停顿时间
  XX:GCRatio //直接设置吞吐量的大小
  ~~~

- ![image-20230129150848779](C:\Users\Dear~柘木塘\AppData\Roaming\Typora\typora-user-images\image-20230129150848779.png)

#### JUC

#### 设计模式

- IO设计模式
- `Synchronized` 的**锁升级**

#### 注解



#### 数据结构

##### 红黑树

红黑树，Red-Black Tree 「RBT」是一个自平衡(不是绝对的平衡)的二叉查找树(BST)，树上的每个节点都遵循下面的规则:

1. 每个节点都有红色或黑色
2. 树的根始终是黑色的 (黑土地孕育黑树根， )
3. 没有两个相邻的红色节点（红色节点不能有红色父节点或红色子节点，**并没有说不能出现连续的黑色节点**）
4. 从节点（包括根）到其任何后代NULL节点(叶子结点下方挂的两个空节点，并且认为他们是黑色的)的每条路径都具有相同数量的黑色节点

#### 集合的扩容

- hashtable

  - **初始大小**：11
  - **每次扩充容量大小**：2n+1
- hashMap:

  - **初始大小**：16
  - **每次扩充容量大小**：2^n
- **底层数据结构：** JDK1.8 以后的 `HashMap` 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树），以减少搜索时间（后文中我会结合源码对这一过程进行分析）。
- ArrayList
  - **初始大小**：10
  - **每次扩充容量大小**：1.5n





#### 模式

##### 两阶段 终止模式

> 优雅的处理后事

~~~java
//利用 isInterrupted
private static void test4() throws InterruptedException {
        Thread t2 = new Thread(() -> {
            while (true) {
                Thread current = Thread.currentThread();
                boolean interrupted = current.isInterrupted();
                if (interrupted) {
                    log.debug(" 打断状态: {}", interrupted);
                    break;
                }
            }
        }, "t2");
        t2.start();
        sleep(500);
        t2.interrupt();
    }
~~~



传统IO工作流程

![image-20230201105345407](C:\Users\Dear~柘木塘\AppData\Roaming\Typora\typora-user-images\image-20230201105345407.png)



#### 常用文件

##### AOF

> redis的持久化文件，记录的是指令，如set a 10

- 特性
  1. 支持重写
  2. 子进程写入，写时复制
  3. 有三种磁盘写入策略
     1. always
     2. no
     3. 每个1s

##### RDB

> redis的持久化文件，记录的是数据。RDB 恢复数据的效率会比 AOF 高些，丢失的影响更大

- 特性

  1. save主进程写入，bgsave子进程写入

  2. 通过配置文件的选项来实现每隔一段时间自动执行一次 bgsave 命令，默认会提供以下配置：

     ```text
     //900 秒之内，对数据库进行了至少 1 次修改就会执行bgsave
     save 900 1
     save 300 10
     save 60 10000
     ```

  3. 写时复制

##### undolog

> undo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undo
> log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的
> update记录。当执行rollback时，就可以从undo log中的逻辑记录读取到相应的内容并进行回滚。

##### redolog

> 重做日志，记录的是事务提交时数据页的物理修改，是用来实现事务的持久性。
> 该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log
> file）,前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都存到该日志文件中, 用
> 于在刷新脏页到磁盘,发生错误时, 进行数据恢复使用。

###### 刷盘时机

`InnoDB` 存储引擎为 `redo log` 的刷盘策略提供了 `innodb_flush_log_at_trx_commit` 参数，它支持三种策略：

- **0** ：设置为 0 的时候，表示每次事务提交时不进行刷盘操作
- **1** ：设置为 1 的时候，表示每次事务提交时都将进行刷盘操作（默认值）
- **2** ：设置为 2 的时候，表示每次事务提交时都只把 redo log buffer 内容写入 page cache

`innodb_flush_log_at_trx_commit` 参数默认为 1 ，也就是说当事务提交时会调用 `fsync` 对 redo log 进行刷盘

另外，`InnoDB` 存储引擎有一个后台线程，每隔`1` 秒，就会把 `redo log buffer` 中的内容写到文件系统缓存（`page cache`），然后调用 `fsync` 刷盘。

除了后台线程每秒`1`次的轮询操作，还有一种情况，当 `redo log buffer` 占用的空间即将达到 `innodb_log_buffer_size` 一半的时候，后台线程会主动刷盘。



##### binlog

> `binlog` 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于`MySQL Server` 层。
>
> 不管用什么存储引擎，只要发生了表数据更新，都会产生 `binlog` 日志

`binlog`会记录所有涉及更新数据的逻辑操作，并且是顺序写

###### 记录格式

- **statement**：原文
- **row**:包含具体数据
- **mixed**：混合





#### 集群一致性问题

##### 主从复制

- redis

  1. 实现

     我们可以使用 `replicaof`（Redis 5.0 之前使用 slaveof）命令形成主服务器和从服务器的关系。

     ```text
     # 服务器 B 执行这条命令
     replicaof <服务器 A 的 IP 地址> <服务器 A 的 Redis 端口号>
     ```

  2. 第一次同步

     主从服务器间的第一次同步的过程可分为三个阶段：

     - 第一阶段是建立链接、协商同步；

       从服务器发送请求同步信号**psync**，并发送主服务器的**runid**，第一次因为未知所以是？和复制进度**offset**，第一次为-1

       主服务器收到后回复**FULLRESYNC**全量复制和**runid**以及**offset**

     - 第二阶段是主服务器同步数据给从服务器；

       通常使用bgsave命令，通过子进程生成RDB并发送，新写入的命令放在**replication buffer 缓冲区里**

     - 第三阶段是主服务器发送新写操作命令给从服务器。

     ![image-20230405131544637](C:\Users\Dear~柘木塘\AppData\Roaming\Typora\typora-user-images\image-20230405131544637.png)

     

  3. 特点：

     从服务器也可以作为主服务器来分担主服务器的压力，因为生成并发送AOF文件时很吃性能的

  4. 后续同步：

     > 主从服务器在完成第一次同步后，就会基于长连接进行命令传播。

     第一次同步完成后，主从服务器都会维护着一个长连接，主服务器在接收到写操作命令后，就会通过这个连接将写命令传播给从服务器，来保证主从服务器的数据一致性。

  5. 增量复制

     > 因网络等原因从服务器和主服务器断开连接后，之后重新连接上会有明显的数据不同步问题，如果重新全量复制开销有太大，所以考虑使用增量复制

     <img src="C:\Users\Dear~柘木塘\AppData\Roaming\Typora\typora-user-images\image-20230405134520294.png" alt="image-20230405134520294" style="zoom: 67%;" />

     主要有三个步骤：

     - 从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的 psync 命令里的 offset 参数不是 -1；
     - 主服务器收到该命令后，然后用 **CONTINUE** 响应命令告诉从服务器接下来采用增量复制的方式同步数据；
     - 然后主服务将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令。

     那么关键的问题来了，**主服务器怎么知道要将哪些增量数据发送给从服务器呢？**

     答案藏在这两个东西里：

     - **repl_backlog_buffer**，是一个「**环形**」缓冲区，用于主从服务器断连后，从中找到差异的数据；
     - **replication offset**，标记上面那个缓冲区的同步进度，主从服务器都有各自的偏移量，主服务器使用 master_repl_offset 来记录自己「*写*」到的位置，从服务器使用 slave_repl_offset 来记录自己「*读*」到的位置。

     那 repl_backlog_buffer 缓冲区是什么时候写入的呢？

     在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里，因此 这个缓冲区里会保存着最近传播的写命令。

     网络断开后，当从服务器重新连上主服务器时，从服务器会通过 psync 命令将自己的复制偏移量 slave_repl_offset 发送给主服务器，主服务器根据自己的  master_repl_offset 和 slave_repl_offset 之间的差距，然后来决定对从服务器执行哪种同步操作：

     - 如果判断出从服务器要读取的数据还在 repl_backlog_buffer 缓冲区里，那么主服务器将采用**增量同步**的方式；
     - 相反，如果判断出从服务器要读取的数据已经不存在 repl_backlog_buffer 缓冲区里，那么主服务器将采用**全量同步**的方式。

##### 读写分离

- redis

  主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。

  ![image-20230405130923063](C:\Users\Dear~柘木塘\AppData\Roaming\Typora\typora-user-images\image-20230405130923063.png)







#### RabbitMQ

> 消息队列，主要用来做流量削峰、解耦、异步

- 缺点：
  1. 可用性降低
  2. 复杂性增加

- MQ选型

  ![image-20230407195538334](C:\Users\Dear~柘木塘\AppData\Roaming\Typora\typora-user-images\image-20230407195538334.png)

  综合上面的材料得出以下两点:

  1. 中小型软件公司，建议选RabbitMQ.一方面，erlang语言天生具备高并发的特性，而且他的管理界面用起来十分方便。正所谓，成也萧何，败也萧何！他的弊端也在这里，虽然RabbitMQ是开源的，然而国内有几个能定制化开发erlang的程序员呢？所幸，RabbitMQ的社区十分活跃，可以解决开发过程中遇到的bug，这点对于中小型公司来说十分重要。不考虑rocketmq和kafka的原因是，一方面中小型软件公司不如互联网公司，数据量没那么大，选消息中间件，应首选功能比较完备的，所以kafka排除。不考虑rocketmq的原因是，rocketmq是阿里出品，如果阿里放弃维护rocketmq，中小型公司一般抽不出人来进行rocketmq的定制化开发，因此不推荐。
  2. 大型软件公司，根据具体使用在rocketMq和kafka之间二选一。一方面，大型软件公司，具备足够的资金搭建分布式环境，也具备足够大的数据量。针对rocketMQ,大型软件公司也可以抽出人手对rocketMQ进行定制化开发，毕竟国内有能力改JAVA源码的人，还是相当多的。至于kafka，根据业务场景选择，如果有日志采集功能，肯定是首选kafka了。具体该选哪个，看使用场景。

- 基本组成

  <img src="C:\Users\Dear~柘木塘\AppData\Roaming\Typora\typora-user-images\image-20230407195937737.png" alt="image-20230407195937737" style="zoom:80%;" />

  

  - Producer

    负责消息的发送

  - Channel

    一个TCP长连接里的内部逻辑连接，节省开销，AMQP method 包含了 channel id 帮助客户端和 message broker 识别 channel，所以 channel 之间是完全隔离的

  - Broder（接收和分发消息的应用）

    - Exchange

      > message 到达 broker 的第一站，根据Rounting key与Queue相连接，常用的类型有：
      >
      > direct (point-to-point)
      >
      > topic (publish-subscribe)
      >
      > fanout(multicast)

      - 死信交换机
      - 延迟

    - Queue

      > 消息到达队列被消费者消费

  - Consumer

    > 处理消息

- 常见问题

  - 消息应答

    > 消息需要知道有没有被消费者消费，消费者通过应答告诉mq

    - 自动应答

      消息发送后立即被认为已经传送成功，高效但不安全

    - 手动应答

      - 单个应答：Multiple=false
      - 批量应答：Multiple=true

    - 应答的方法

      - Channel.basicAck(用于肯定确认)

        RabbitMQ 已知道该消息并且成功的处理消息，可以将其丢弃了

      - Channel.basicNack(用于否定确认)

      - Channel.basicReject(用于否定确认)
        与 Channel.basicNack 相比少一个参数，不处理该消息了直接拒绝，可以将其丢弃了

  - 持久化

    - 持久化队列

      RabbitMQ 默认情况下，队列是非持久化的，当 RabbitMQ 服务停止或异常关闭时，队列中的消息会被删除。为了避免这种情况，可以使用 durable 标记将队列标记为持久化的，这样即使 RabbitMQ 服务重启，队列也不会被删除。将队列持久化有助于确保在 RabbitMQ 服务异常关闭或宕机的情况下，消息不会丢失。

    - 持久化消息

      将消息标记为持久化，意味着在 RabbitMQ 服务异常关闭或宕机的情况下，消息不会丢失。将消息标记为持久化需要两个条件：1）将队列标记为持久化的；2）在发送消息时将消息标记为持久化的。需要注意的是，将消息标记为持久化的代价是降低了 RabbitMQ 的吞吐量。因此，在考虑是否将消息标记为持久化时，需要根据具体的应用场景进行权衡。

    - 交换机持久化

      在 RabbitMQ 中，交换机可以是持久化的或非持久化的。将交换机标记为持久化的可以确保在 RabbitMQ 服务异常关闭或宕机的情况下，交换机不会丢失。交换机持久化是通过在创建交换机时设置 durable 标记实现的。需要注意的是，将交换机标记为持久化的代价是增加了 RabbitMQ 的开销，因此在创建交换机时需要进行权衡。

  - 不公平分发

    - 根据消费者消费能力的不同

      另一种实现消息的不公平分发的方式是基于消费者的能力。可以通过设置消费者的 prefetchCount 属性，控制每个消费者能够获取的消息数量。在这种方式下，RabbitMQ 会将一定数量的消息分配给每个消费者，而不是一条一条地分配。这样做可以确保某些消费者处理更多的消息，而某些消费者处理较少的消息。

    - 根据消费者的优先级

      在 RabbitMQ 中，可以通过设置消费者的优先级来实现消息的不公平分发。消费者的优先级越高，就越容易获取到消息。当多个消费者同时请求获取消息时，RabbitMQ 会优先将消息分配给优先级高的消费者。

  - 发布确认

    - 单个确认

      同步确认，速度很慢

    - 批量确认

      不好确定哪个消息出问题

    - 异步确认

      实现复杂，但速度快

    - 怎么处理未确认消息

      最好的解决的解决方案就是把未确认的消息放到一个基于内存的能被发布线程访问的队列，比如说ConcurrentLinkedQueue这个队列在 confirm callbacks 与发布线程之间进行消息的传递。

  - 死信问题

    - 死信
      1. 概念：就是无法被消费的消息，某些时候由于特定的原因导致 queue 中的某些消息无法被消费，这样的消息如果没有
         后续的处理，就变成了死信
      2. 来源：
         1. 消息 TTL 过期
         2. 队列达到最大长度(队列满了，无法再添加数据到 mq 中)
         3. 消息被拒绝(basic.reject 或 basic.nack)并且 requeue=false.

  - TTL问题

    - 队列设置TTL

      如果设置了队列的 TTL 属性，那么一旦消息过期，就会被队列丢弃(如果配置了死信队列被丢到死信队列中)

    - 消息TTL

      而第二种方式，消息即使过期，也不一定会被马上丢弃，因为消息是否过期是在即将投递到消费者之前判定的，如果当前队列有严重的消息积压情况，则已过期的消息也许还能存活较长时间；另外，还需要注意的一点是，如果不设置 TTL，表示消息永远不会过期，如果将 TTL 设置为 0，则表示除非此时可以直接投递该消息到消费者，否则该消息将会被丢弃

  - 延时队列

    > 延时队列就是用来存放需要在指定时间被处理的元素的队列

    1. 给队列设置TTL，过时了的消息就到死信队列中，问题就是每增加一个新的时间需求，就要新增一个队列

       ![image-20230407210347091](C:\Users\Dear~柘木塘\AppData\Roaming\Typora\typora-user-images\image-20230407210347091.png)

    2. Rabbitmq 插件实现延迟队列，就可以将交换机设置成延时交换机

       **原理**：在我们自定义的交换机中，这是一种新的交换类型，该类型消息支持延迟投递机制 消息传递后并不会立即投递到目标队列中，而是存储在 mnesia(一个分布式数据系统)表中，当达到投递时间时，才投递到目标队列中。

    3. Java的DelayQueue

    4. Redis的zset

    5. Quartz

    6. kafka的时间轮

  - 发布确认高级

    > 在生产环境中由于一些不明原因，导致 rabbitmq 重启，在 RabbitMQ 重启期间生产者消息投递失败，
    > 导致消息丢失，需要手动处理和恢复。于是，我们开始思考，如何才能进行 RabbitMQ 的消息可靠投递呢？

    <img src="C:\Users\Dear~柘木塘\AppData\Roaming\Typora\typora-user-images\image-20230407211201756.png" alt="image-20230407211201756" style="zoom:80%;" />

    - 配置文件

      spring.rabbitmq.publisher-confirm-type=

      - NONE
        禁用发布确认模式，是默认值

      - CORRELATED
        发布消息成功到交换器后会触发回调方法

      - SIMPLE

        经测试有两种效果，其一效果和 CORRELATED 值一样会触发回调方法，其二在发布消息成功后使用 rabbitTemplate 调用 waitForConfirms 或 waitForConfirmsOrDie 方法等待 broker 节点返回发送结果，根据返回结果来判定下一步的逻辑，要注意的点是waitForConfirmsOrDie 方法如果返回 false 则会关闭 channel，则接下来无法发送消息到 broker

  - 交换机未匹配到队列的消息

    > 仅开启了生产者确认机制的情况下，交换机接收到消息后，会直接给消息生产者发送确认消息，如果发现该消息不可路由，那么消息会被直接丢弃，此时生产者是不知道消息被丢弃这个事件的

    1. 使用 Mandatory 参数

       通过设置 mandatory 参数可以在当消息传递过程中不可达目的地时将消息返回给生产者。

    2. 备份交换机

       ~~~text
       什么是备份交换机呢？
       备份交换机可以理解为 RabbitMQ 中交换机的“备胎”，当我们为某一个交换机声明一个对应的备份交换机时，
       就是为它创建一个备胎，当交换机接收到一条不可路由消息时，将会把这条消息转发到备份交换机中，由
       备份交换机来进行转发和处理，通常备份交换机的类型为 Fanout ，这样就能把所有消息都投递到与其绑
       定的队列中，然后我们在备份交换机下绑定一个队列，这样所有那些原交换机无法被路由的消息，就会都
       进入这个队列了。当然，我们还可以建立一个报警队列，用独立的消费者来进行监测和报警。
       ~~~

  - 幂等性问题

    1. 唯一id+指纹吗
    2. redis的setnx

  - 优先级

    要让队列实现优先级需要做的事情有如下事情:队列需要设置为优先级队列，消息需要设置消息的优先
    级，消费者需要等待消息已经发送到队列中才去消费因为，这样才有机会对消息进行排序

  - 惰性队列

    惰性队列会尽可能的将消息存入磁盘中，而在消费者消费到相应的消息时才会被加载到内存中，它的一个重要的设计目标是能够支持更长的队列，即支持更多的消息存储。当消费者由于各种各样的原因(比如消费者下线、宕机亦或者是由于维护而关闭等)而致使长时间内不能消费消息造成堆积时，惰性队列就很有必要了。
